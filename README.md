# Smart Banking Transactions Data Engineering Pipeline (PySpark)

A complete **Data Engineering portfolio project** built using **PySpark** and the **Medallion Architecture (Bronze â†’ Silver â†’ Gold)**.

This project simulates how banks process millions of transactions daily by ingesting raw CSV transaction records, cleaning and enriching them, applying fraud detection rules, building a Star Schema, and generating business analytics KPIs.

---

## ğŸš€ Project Overview

Banks generate large volumes of financial transaction data every day.  
To support fraud analytics, customer insights, and reporting, raw transaction records must be transformed into clean, structured datasets.

This pipeline performs:

- Raw ingestion into a Data Lake (Bronze)
- Data cleaning and enrichment (Silver)
- Fraud rule flagging and anomaly detection
- Star Schema modeling for analytics (Gold)
- Business KPI queries for insights

---

## ğŸ— Pipeline Architecture (Medallion Design)

Raw CSV Transactions  
â†’ Bronze Layer (Raw Parquet)  
â†’ Silver Layer (Clean + Fraud Flagged Parquet)  
â†’ Gold Layer (Star Schema Tables)  
â†’ Business Queries + KPI Reports

---

## ğŸ“‚ Project Structure

banking_data_pipeline/

- main.py  
- config.py  
- requirements.txt  

data/  
- transactions.csv  

jobs/  
- bronze_ingestion.py  
- silver_cleaning.py  
- fraud_detection.py  
- gold_star_schema.py  
- business_queries.py  

utils/  
- spark_session.py  
- schema_definitions.py  
- helpers.py  

output/  
- bronze/  
- silver/  
- gold/  
- reports/  

---

## ğŸ“Œ Sample Dataset

File: `data/transactions.csv`

```csv
txn_id,customer_id,customer_name,account_type,merchant,category,amount,txn_date,city
1001,C001,John Smith,Savings,Amazon,Shopping,250,2025-01-05,New York
1002,C002,Amina Rahman,Checking,Walmart,Grocery,80,2025-01-06,Boston
1003,C003,Sarah Lee,Credit,Apple,Electronics,1200,2025-01-08,Chicago
1004,C001,John Smith,Credit,Casino,Gambling,5000,2025-01-10,Las Vegas
```

---

## âš™ï¸ Technologies Used

- Python  
- PySpark  
- Parquet Storage Format  
- Medallion Data Lake Architecture  
- Fraud Analytics Engineering  
- Star Schema Modeling  
- Business KPI Queries  

---

## ğŸš€ Pipeline Jobs

### ğŸ¥‰ Bronze Layer: Raw Ingestion
Reads raw CSV and stores raw Parquet output.

Output:
output/bronze/

---

### ğŸ¥ˆ Silver Layer: Cleaning & Transformation
Applies:
- Duplicate removal  
- Null handling  
- Date conversion  
- Derived metrics  

Output:
output/silver/

---

### ğŸš¨ Fraud Detection Layer
Flags suspicious transactions such as:
- Amount > $3000  
- Gambling/Casino merchants  
- Category anomalies  

Output:
output/silver/fraud_flagged/

---

### ğŸ¥‡ Gold Layer: Star Schema Modeling
Creates analytics-ready tables:

Dimensions:
- dim_customer  
- dim_merchant  

Fact Table:
- fact_transactions  

Output:
output/gold/

---

### ğŸ“Š Business Analytics Queries
Generates KPIs such as:
- Top spending customers  
- Fraud transaction percentage  
- Revenue by merchant  
- Spending by city  

---

## â–¶ï¸ How to Run the Project

Install dependencies:

```bash
pip install -r requirements.txt
```

Run the pipeline:

```bash
python main.py
```

---

## ğŸ“ Git Commit Strategy (50 Commits)

Phase 1: Setup (1â€“10)  
Phase 2: Silver Cleaning (11â€“25)  
Phase 3: Fraud Detection (26â€“35)  
Phase 4: Gold Star Schema (36â€“45)  
Phase 5: Business Queries (46â€“50)

---

## ğŸ“Œ Future Enhancements

- Integrate AWS S3 + Glue Catalog  
- Load Gold tables into Redshift/Snowflake  
- Add Kafka streaming ingestion  
- Orchestrate pipeline using Airflow  
- Add ML-based fraud prediction  

---

## ğŸ‘¨â€ğŸ’» Author

Md Shahedur Rahman  
Masterâ€™s in Computer Science (NYU)  
Data Engineering | PySpark | SQL | Cloud Pipelines  
